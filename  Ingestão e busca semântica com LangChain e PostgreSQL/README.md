# ğŸ¤– Assistente IA RAG - Sistema de Busca SemÃ¢ntica com LLM

<div align="center">
  
  ![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
  ![LangChain](https://img.shields.io/badge/LangChain-0.3.27-green.svg)
  ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-17-336791.svg)
  ![OpenAI](https://img.shields.io/badge/OpenAI-API-412991.svg)
  ![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)
  
  <h3>Sistema inteligente de processamento e consulta de documentos PDF usando RAG (Retrieval-Augmented Generation)</h3>
   
</div>

---

## ğŸ“– Sobre

Este projeto implementa um **Assistente IA com RAG** (Retrieval-Augmented Generation) que permite carregar documentos PDF, processar seu conteÃºdo e fazer perguntas contextualizadas sobre o material. O sistema utiliza embeddings vetoriais para busca semÃ¢ntica e modelos de linguagem para gerar respostas precisas baseadas apenas no contexto dos documentos carregados.

### âœ¨ Principais Funcionalidades

- ğŸ“„ **IngestÃ£o de Documentos PDF**: Carregamento e processamento automÃ¡tico de arquivos PDF
- ğŸ” **Busca SemÃ¢ntica AvanÃ§ada**: Utiliza embeddings OpenAI para encontrar informaÃ§Ãµes relevantes
- ğŸ’¬ **Chat Contextualizado**: Respostas baseadas exclusivamente no conteÃºdo dos documentos
- ğŸ¨ **Interface CLI Interativa**: Terminal colorido e amigÃ¡vel com feedback visual
- ğŸ—„ï¸ **Armazenamento Vetorial**: PostgreSQL com pgvector para persistÃªncia eficiente
- âš¡ **Performance Otimizada**: Chunking inteligente e cache de embeddings

## ğŸ—ï¸ Arquitetura

```mermaid
graph TB
    A[ğŸ“± Interface CLI] --> B[ğŸ¤– Chat Engine]
    B --> C[ğŸ” Search Module]
    C --> D[ğŸ—„ï¸ PostgreSQL + pgvector]
    
    E[ğŸ“„ PDF Document] --> F[ğŸ“š Ingest Module]
    F --> G[âœ‚ï¸ Text Splitter]
    G --> H[ğŸ§® OpenAI Embeddings]
    H --> D
    
    C --> I[ğŸ¯ Similarity Search]
    I --> J[ğŸ“ Context Builder]
    J --> K[ğŸ¤– LLM OpenAI]
    K --> L[ğŸ’¬ Resposta Contextualizada]
    
    style A fill:#e1f5fe
    style D fill:#fff3e0
    style K fill:#f3e5f5
```

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- **Python 3.9+**
- **Docker e Docker Compose**
- **Conta OpenAI com API Key**
- **8GB RAM mÃ­nimo recomendado**

### ğŸ“‹ Passo a Passo

#### 1ï¸âƒ£ Clone o RepositÃ³rio

```bash
git clone https://github.com/seu-usuario/desafios-tecnicos-MBA-IA.git
cd desafios-tecnicos-MBA-IA
```

#### 2ï¸âƒ£ Configure o Ambiente Virtual

```bash
# Criar ambiente virtual
python3 -m venv venv

# Ativar ambiente virtual
# Linux/Mac:
source venv/bin/activate

# Windows:
venv\Scripts\activate
```

#### 3ï¸âƒ£ Instale as DependÃªncias

```bash
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Configure as VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:

```env
# OpenAI Configuration
OPENAI_API_KEY=sua-chave-api-openai-aqui
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Database Configuration
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/rag
PG_VECTOR_COLLECTION_NAME=documents

# Optional: Path for testing
PDF_PATH=document.pdf
```

> ğŸ’¡ **Dica**: Obtenha sua API Key em [platform.openai.com/api-keys](https://platform.openai.com/api-keys)

#### 5ï¸âƒ£ Inicie o Banco de Dados

```bash
# Iniciar PostgreSQL com pgvector
docker-compose up -d

# Verificar se estÃ¡ rodando
docker-compose ps
```

## ğŸ® Como Usar

### Iniciando o Assistente

```bash
python src/chat.py
```

### Interface em ExecuÃ§Ã£o

![Assistente IA RAG em execuÃ§Ã£o](exec.png)

### Comandos DisponÃ­veis

| Comando | DescriÃ§Ã£o |
|---------|-----------|
| `add doc` | Adicionar um novo documento PDF ao sistema |
| `exit` | Sair do assistente |
| `[sua pergunta]` | Fazer uma pergunta sobre os documentos carregados |

### ğŸ“ Exemplo de Uso

```bash
# 1. Inicie o assistente
$ python src/chat.py

# 2. Adicione um documento
â”Œâ”€ VocÃª
â””â”€ add doc

ğŸ“ Digite o caminho do documento:
â””â”€ ./relatorio-financeiro.pdf
-> PDF processado com sucesso!

# 3. FaÃ§a perguntas
â”Œâ”€ VocÃª
â””â”€ Qual foi o faturamento total do Ãºltimo trimestre?

â”Œâ”€ ğŸ¤– Assistente IA
â”œâ”€ Processando sua pergunta...
â””â”€ De acordo com o documento, o faturamento total do Ãºltimo trimestre foi de R$ 2.5 milhÃµes...
```

## ğŸ“ Estrutura do Projeto

```
desafios-tecnicos-MBA-IA/
â”‚
â”œâ”€â”€ ğŸ“‚ src/                     # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ ğŸ“„ chat.py              # Interface CLI e loop principal
â”‚   â”œâ”€â”€ ğŸ“„ ingest.py            # Processamento e ingestÃ£o de PDFs
â”‚   â””â”€â”€ ğŸ“„ search.py            # Busca semÃ¢ntica e geraÃ§Ã£o de prompts
â”‚
â”œâ”€â”€ ğŸ“„ docker-compose.yml       # ConfiguraÃ§Ã£o do PostgreSQL + pgvector
â”œâ”€â”€ ğŸ“„ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ .env                     # VariÃ¡veis de ambiente (criar localmente)
â”œâ”€â”€ ğŸ“„ document.pdf             # Documento exemplo para testes
â””â”€â”€ ğŸ“„ README.md               # Este arquivo
```

## ğŸ› ï¸ Stack TecnolÃ³gica

### Core
- **[LangChain](https://langchain.com/)** (v0.3.27) - Framework para aplicaÃ§Ãµes LLM
- **[OpenAI API](https://openai.com/)** - Embeddings e modelo de linguagem
- **[PostgreSQL](https://www.postgresql.org/)** (v17) - Banco de dados principal
- **[pgvector](https://github.com/pgvector/pgvector)** - ExtensÃ£o para busca vetorial

### Bibliotecas Python
- **langchain-openai** - IntegraÃ§Ã£o com OpenAI
- **langchain-postgres** - IntegraÃ§Ã£o com PostgreSQL/pgvector
- **pypdf** - Processamento de arquivos PDF
- **python-dotenv** - Gerenciamento de variÃ¡veis de ambiente
- **psycopg** - Driver PostgreSQL para Python

## ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### Ajuste de ParÃ¢metros

VocÃª pode ajustar os seguintes parÃ¢metros no cÃ³digo:

**Em `ingest.py`:**
```python
# Tamanho dos chunks de texto
chunk_size=1000  # PadrÃ£o: 1000 caracteres
chunk_overlap=150  # PadrÃ£o: 150 caracteres de sobreposiÃ§Ã£o
```

**Em `search.py`:**
```python
# NÃºmero de chunks relevantes para contexto
k=10  # PadrÃ£o: 10 chunks mais similares
```

**Em `chat.py`:**
```python
# Modelo e temperatura
temperature=0.5  # Criatividade das respostas (0-1)
```

## ğŸ“Š Performance e LimitaÃ§Ãµes

### âœ… Pontos Fortes
- Respostas precisas baseadas em contexto
- Suporte a documentos grandes
- Interface intuitiva
- PersistÃªncia de dados

### âš ï¸ LimitaÃ§Ãµes Conhecidas
- Suporte apenas para arquivos PDF
- Requer conexÃ£o com API OpenAI
- Custo por token processado
- Limite de contexto do modelo LLM
